{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Music_generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Javcm/Deep-Learning/blob/main/Music_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MVRg1xDdF-d"
      },
      "source": [
        "##Considera un corpus de obras (cortas) de piano en formato `MIDI` como las que se encuentran en la carpeta `midi_train`.
        El corpus usado en este notebook se encuentra en esta carpeta libre de Drive 
        https://drive.google.com/drive/folders/1bo7M6M59yDdZ7G0JA-bDtW2mjejfvyX5?usp=sharing
        "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0FlyW2adF-e",
        "outputId": "c87d0bc0-80c2-4136-c9da-6a1de24afd7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pickle\n",
        "import numpy\n",
        "import os\n",
        "import keras\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "from IPython.display import Image\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,LSTM,Activation,BatchNormalization\n",
        "from keras.utils import np_utils, plot_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "#os.chdir('/home/victor/cursos/optativa2020/')\n",
        "# el directorio con el corpus de entrenamiento\n",
        "midi_songs = '/content/gdrive/My Drive/T4 DL/classic_piano_corpus/midi_train'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9PK7dtJdF-h"
      },
      "source": [
        "Pongo en la página unos MIDIs de entrenamiento, pero lo que recomiendo es que cada quien forme su corpus de entrenamiento. Yo obtuve los midi de http://www.piano-midi.de/midicoll.htm pero también puedes buscar otra fuente.\n",
        "\n",
        "La parte que sigue puede usarse para el proceso de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfv03lM3dF-h"
      },
      "source": [
        "def get_notes():\n",
        "    \"\"\" Obtiene las notas y acordes de los archivos midi que se encuentran en el directorio /midi_songs \"\"\"\n",
        "    notes = []\n",
        "\n",
        "    for file in os.scandir(midi_songs):\n",
        "        print(file.path)\n",
        "        midi = converter.parse(file.path)\n",
        "\n",
        "        print(\"Analizando %s\" % file.name)\n",
        "\n",
        "        notes_to_parse = None\n",
        "\n",
        "        # en esta parte, se extraen todas las notas del archivo midi\n",
        "        # como 'midi' es un objeto Score (que a su vez hereda de un Stream),\n",
        "        # pueden accederse a todas las partes de la partitura (Score)\n",
        "        \n",
        "        # se consideran los casos en que el archivo midi tenga partes que correspondan a diferentes instrumentos\n",
        "        # (solo se usa el primero, aunque puedan haber mas de 1), o que tenga solo las notas\n",
        "        midi_parts = instrument.partitionByInstrument(midi)\n",
        "        if midi_parts: \n",
        "            notes_to_parse = midi_parts.parts[0].recurse() \n",
        "        else: # notas en estructura flat\n",
        "            notes_to_parse = midi.flat.notes\n",
        "\n",
        "        for element in notes_to_parse:\n",
        "            if isinstance(element, note.Note):\n",
        "                notes.append(str(element.pitch))\n",
        "            elif isinstance(element, chord.Chord):\n",
        "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    # guarda las notas. Este paso es muy importante, ya que se usaran en la fase de test,\n",
        "    # es decir, cuando se generan notas a partir del modelo entrenado\n",
        "    with open('/content/gdrive/My Drive/T4 DL/data_mid/notes', 'wb') as filepath:\n",
        "        pickle.dump(notes, filepath)\n",
        "\n",
        "    return notes\n",
        "\n",
        "\n",
        "def prepare_sequences(notes, n_vocab, sequence_length):\n",
        "    \"\"\" Prepara las secuencias a usar en el modelo \"\"\"\n",
        "\n",
        "    # nuestro 'vocabulario' consiste en todas las notas unicas de los archivos midi\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "     # se crea un diccionario para mapear notas a enteros\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # crea las secuencias de entrada y las salidas\n",
        "    # podria usarse para una arquitectura 'many to one', pero también puedes\n",
        "    # hacer un stack de RNNs (many to many)\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # redimensiona las secuencias de entrada para la RNN a usar\n",
        "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normaliza\n",
        "    network_input = network_input / float(n_vocab)\n",
        "\n",
        "    network_output = np_utils.to_categorical(network_output)\n",
        "\n",
        "    return (network_input, network_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwbTCaokdF-j"
      },
      "source": [
        "notes = get_notes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80LrPYmTdF-l",
        "outputId": "8588728e-7c17-4971-d9b8-d890ad3228c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# puedes probar con varios longitudes de secuencias...\n",
        "sequence = 50\n",
        "# cantidad de notas\n",
        "n_vocab = len(set(notes))\n",
        "print('vocabulario:', n_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocabulario: 416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGC-nfkfdF-o",
        "outputId": "6bd2a831-ca2d-40ab-d8f0-37af890be177",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "network_input, network_output = prepare_sequences(notes, n_vocab, sequence)\n",
        "print(np.shape(network_input),np.shape(network_output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(154379, 50, 1) (154379, 416)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sls1KLYodF-q"
      },
      "source": [
        "No pongo el código del modelo que usé, pero en mi caso, usé la siguiente arquitectura. Puedes probar con ésa misma o alguna otra que tú sugieras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vz0_37F-7n1"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256,input_shape=(network_input.shape[1], network_input.shape[2]),return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(512, return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(256))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(n_vocab))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "#plot_model(model,show_shapes=True)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AawbVnWsdF-q",
        "outputId": "e03af096-4a6f-4d68-d5fe-7b8b1b0f70fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Image(retina=True, filename='/home/victor/cursos/figs/midi_LSTM.png')\n",
        "filepath = \"/content/gdrive/My Drive/T4 DL/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"  \n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath, monitor='loss', \n",
        "    verbose=0,        \n",
        "    save_best_only=True,        \n",
        "    mode='min'\n",
        ")    \n",
        "callbacks_list = [checkpoint]     \n",
        "model.fit(network_input, network_output, epochs=100, batch_size=64, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2413/2413 [==============================] - 61s 25ms/step - loss: 4.7004\n",
            "Epoch 2/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 4.6503\n",
            "Epoch 3/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 4.6253\n",
            "Epoch 4/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 4.5744\n",
            "Epoch 5/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 4.5060\n",
            "Epoch 6/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 4.4117\n",
            "Epoch 7/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 4.3115\n",
            "Epoch 8/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 4.2027\n",
            "Epoch 9/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 4.0756\n",
            "Epoch 10/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 3.9643\n",
            "Epoch 11/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 3.8591\n",
            "Epoch 12/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 3.7573\n",
            "Epoch 13/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 3.6699\n",
            "Epoch 14/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 3.5865\n",
            "Epoch 15/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 3.5093\n",
            "Epoch 16/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 3.4393\n",
            "Epoch 17/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 3.3824\n",
            "Epoch 18/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 3.3176\n",
            "Epoch 19/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 3.2604\n",
            "Epoch 20/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 3.2059\n",
            "Epoch 21/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 3.1640\n",
            "Epoch 22/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 3.1213\n",
            "Epoch 23/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 3.0801\n",
            "Epoch 24/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 3.0437\n",
            "Epoch 25/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 3.0022\n",
            "Epoch 26/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.9739\n",
            "Epoch 27/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.9381\n",
            "Epoch 28/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.9120\n",
            "Epoch 29/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.8799\n",
            "Epoch 30/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.8507\n",
            "Epoch 31/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.8269\n",
            "Epoch 32/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.8007\n",
            "Epoch 33/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.7811\n",
            "Epoch 34/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.7606\n",
            "Epoch 35/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.7395\n",
            "Epoch 36/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.7195\n",
            "Epoch 37/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.7005\n",
            "Epoch 38/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.6836\n",
            "Epoch 39/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.6600\n",
            "Epoch 40/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.6476\n",
            "Epoch 41/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.6370\n",
            "Epoch 42/100\n",
            "2413/2413 [==============================] - 65s 27ms/step - loss: 2.6235\n",
            "Epoch 43/100\n",
            "2413/2413 [==============================] - 65s 27ms/step - loss: 2.5992\n",
            "Epoch 44/100\n",
            "2413/2413 [==============================] - 65s 27ms/step - loss: 2.5907\n",
            "Epoch 45/100\n",
            "2413/2413 [==============================] - 65s 27ms/step - loss: 2.5815\n",
            "Epoch 46/100\n",
            "2413/2413 [==============================] - 65s 27ms/step - loss: 2.5740\n",
            "Epoch 47/100\n",
            "2413/2413 [==============================] - 65s 27ms/step - loss: 2.5536\n",
            "Epoch 48/100\n",
            "2413/2413 [==============================] - 65s 27ms/step - loss: 2.5445\n",
            "Epoch 49/100\n",
            "2413/2413 [==============================] - 65s 27ms/step - loss: 2.5255\n",
            "Epoch 50/100\n",
            "2413/2413 [==============================] - 65s 27ms/step - loss: 2.5163\n",
            "Epoch 51/100\n",
            "2413/2413 [==============================] - 65s 27ms/step - loss: 2.5087\n",
            "Epoch 52/100\n",
            "2413/2413 [==============================] - 65s 27ms/step - loss: 2.4948\n",
            "Epoch 53/100\n",
            "2413/2413 [==============================] - 65s 27ms/step - loss: 2.4782\n",
            "Epoch 54/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.4783\n",
            "Epoch 55/100\n",
            "2413/2413 [==============================] - 65s 27ms/step - loss: 2.4697\n",
            "Epoch 56/100\n",
            "2413/2413 [==============================] - 65s 27ms/step - loss: 2.4525\n",
            "Epoch 57/100\n",
            "2413/2413 [==============================] - 65s 27ms/step - loss: 2.4517\n",
            "Epoch 58/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.4379\n",
            "Epoch 59/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.4422\n",
            "Epoch 60/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.4204\n",
            "Epoch 61/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.4176\n",
            "Epoch 62/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.4045\n",
            "Epoch 63/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.4054\n",
            "Epoch 64/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.3958\n",
            "Epoch 65/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.3802\n",
            "Epoch 66/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.3774\n",
            "Epoch 67/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.3650\n",
            "Epoch 68/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.3630\n",
            "Epoch 69/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.3498\n",
            "Epoch 70/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.3443\n",
            "Epoch 71/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.3441\n",
            "Epoch 72/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.3360\n",
            "Epoch 73/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.3236\n",
            "Epoch 74/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.3155\n",
            "Epoch 75/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.3158\n",
            "Epoch 76/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.3107\n",
            "Epoch 77/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.2998\n",
            "Epoch 78/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.2956\n",
            "Epoch 79/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.2869\n",
            "Epoch 80/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.2803\n",
            "Epoch 81/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.2760\n",
            "Epoch 82/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.2674\n",
            "Epoch 83/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.2601\n",
            "Epoch 84/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.2596\n",
            "Epoch 85/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.2511\n",
            "Epoch 86/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.2452\n",
            "Epoch 87/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.2411\n",
            "Epoch 88/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.2370\n",
            "Epoch 89/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.2269\n",
            "Epoch 90/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.2143\n",
            "Epoch 91/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.2173\n",
            "Epoch 92/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.2065\n",
            "Epoch 93/100\n",
            "2413/2413 [==============================] - 64s 27ms/step - loss: 2.2056\n",
            "Epoch 94/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.1883\n",
            "Epoch 95/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.1898\n",
            "Epoch 96/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.1915\n",
            "Epoch 97/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.1802\n",
            "Epoch 98/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.1742\n",
            "Epoch 99/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.1713\n",
            "Epoch 100/100\n",
            "2413/2413 [==============================] - 64s 26ms/step - loss: 2.1644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7feef4707b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0paczYVRzp9i",
        "outputId": "ffdd79fb-48fe-418e-ef8f-162758161b2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights('saved_model/my_model_weights') \n",
        "model.save(\"/content/gdrive/My Drive/T4 DL/my_model.hdf5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdhjv1VYdF-t"
      },
      "source": [
        "Ya que tienes el modelo entrenado y guardado, puedes generar una secuencia y guardarlo en archivo MIDI con el siguiente código"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWj8ZUGVdF-u"
      },
      "source": [
        "def prepare_sequences_test(notes, pitchnames, n_vocab):\n",
        "    \"\"\" Prepara las secuencias para usar en el modelo entrenado \"\"\"\n",
        "    \n",
        "    # aqui, se realiza un mapeo (con diccionario) entre las notas y valores enteros y al reves\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    sequence_length = 100\n",
        "    network_input = []\n",
        "    output = []\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # como antes, redimensionamos las entradas para poder usarse con LSTM\n",
        "    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalizamos la entrada\n",
        "    normalized_input = normalized_input / float(n_vocab)\n",
        "\n",
        "    return (network_input, normalized_input)\n",
        "\n",
        "def generate_notes_test(model, network_input, pitchnames, n_vocab):\n",
        "    \"\"\" Genera notas musicales a partir de una red neuronal basado en una secuencia inicial de notas \"\"\"\n",
        "    \n",
        "    # selecciona una secuencia aleatoria del input a partir de la cual se realizaran predicciones\n",
        "    start = numpy.random.randint(0, len(network_input)-1)\n",
        "\n",
        "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    pattern = network_input[start]\n",
        "    prediction_output = []\n",
        "\n",
        "    # genera 500 notas (puedes cambiarlo)\n",
        "    for note_index in range(500):\n",
        "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "        prediction_input = prediction_input / float(n_vocab)\n",
        "\n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "\n",
        "        index = numpy.argmax(prediction)\n",
        "        result = int_to_note[index]\n",
        "        prediction_output.append(result)\n",
        "\n",
        "        pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "    return prediction_output\n",
        "\n",
        "def create_midi(prediction_output, midfile):\n",
        "    \"\"\" genera un archivo MIDI a partir de las notas generadas (o predichas) \"\"\"\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # crea los objetos fundamentales Note y Chrod basado en los valores genrados por el modelo entrenado\n",
        "    for pattern in prediction_output:\n",
        "        # si las notas forman un acorde...\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                new_note = note.Note(int(current_note))\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # si son notas...\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # incremental el offset en cada iteracion. El offset es la posicion dentro del stream de musica\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "\n",
        "    midi_stream.write('midi', fp = midfile)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOAzxYzydF-y"
      },
      "source": [
        "Suponiendo que ya creaste un modelo (my_model), lo entrenaste y LO GUARDASTE, el siguiente código genera la música a partir de ese modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXkFwXzudF-z",
        "outputId": "523263e7-dca1-4c22-ca4d-d1b7df633a87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\" Genera las notas y el archivo MIDI (piano) \"\"\"\n",
        "\n",
        "# carga las notas usadas cuando se entreno el modelo\n",
        "with open('/content/gdrive/My Drive/T4 DL/data_mid/notes', 'rb') as filepath:\n",
        "    notes = pickle.load(filepath)\n",
        "\n",
        "# Obtiene el nombre de todas las notas (pitches)\n",
        "pitchnames = sorted(set(item for item in notes))\n",
        "n_vocab = len(set(notes))\n",
        "\n",
        "\"\"\" Obtiene las secuencias Genera las notas y el archivo MIDI (piano) \"\"\"\n",
        "network_input, normalized_input = prepare_sequences_test(notes, pitchnames, n_vocab)\n",
        "\n",
        "# carga el modelo entrenado\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/gdrive/My Drive/T4 DL/my_model.hdf5')\n",
        "# genera las notas\n",
        "prediction_output = generate_notes_test(model, network_input, pitchnames, n_vocab)\n",
        "np.save(\"/content/gdrive/My Drive/T4 DL/predicted_notes\",prediction_output)\n",
        "# crea el MIDI\n",
        "create_midi(prediction_output, '/content/gdrive/My Drive/T4 DL/test_output.mid')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 50, 1) for input Tensor(\"lstm_input_1:0\", shape=(None, 50, 1), dtype=float32), but it was called on an input with incompatible shape (None, 100, 1).\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
